---
layout:     post
title:      特征缩放
date:       2018-10-26
author:     Sometimes Naive
header-img: img/black.png
catalog: true
tags:
    - 机器学习
---
# 特征缩放

特征缩放是一种用于标准化变量范围的方法，多用于数据预处理。

## 为什么需要特征算法？

1. 特征缩放可以提高模型的**精度**。例如：分类器需要计算样本之间的距离，如果一个特征的值域范围非常大，那么距离计算就会主要取决于这个特征，导致偏离实际情况。

2. 特征缩放可以提升模型的**收敛速度**。在进行梯度下降时能够获得更快的收敛。

## 方法

**Rescaling (min-max normalization)**：中文名叫线性归一化，最小-最大规范化等等。该方法把特征范围缩放到[0,1]或[-1,1]之间。目标范围的选择取决于数据的性质。

公式为：![](http://ww1.sinaimg.cn/large/9cc52ef9gy1fwknxwbwstj206201k0o5.jpg)

公式比较直观，这里就不作解释。

**Mean normalization**：中文名叫均值归一化。

公式为：![](http://ww1.sinaimg.cn/large/9cc52ef9gy1fwko71nklnj204q01f0si.jpg)

**Standardization**：中文名叫标准化，0均值标准化（zero-mean normalization）。标准化将数据正态化，使得平均值为0，标准差为1。它要求原数据的分布能够近似正态分布，不然效果没那么好。但是，根据中心极限定理，如果数据量足够大，那么也可以服从正态分布。

公式为：![](http://ww1.sinaimg.cn/large/9cc52ef9gy1fwkobpn1fuj202t01k0qi.jpg)

**Scaling to unit length**：中文名叫缩放单位长度或归一化到单位长度向量。该方法实际上是将向量除以向量的欧几里得长度。

公式为：![](http://ww1.sinaimg.cn/large/9cc52ef9gy1fwkonq24smj202m0180nv.jpg)

## 归一化和标准化的适用范围

> - 如果对输出结果范围有要求，用归一化
>
> - 如果数据较为稳定，不存在极端的最大最小值，用归一化
>
> - 如果数据存在异常值和较多噪音，用标准化
>
>   ​			——引用自知乎大V微调（文末有链接）

## 总结

实际上，归一化和标准化都差不多，都是对数据进行预处理，从而使得数据落入统一的数值范围，获得更好的训练效果。

## 参考

[Feature scaling](https://en.wikipedia.org/wiki/Feature_scaling)

[特征工程中的「归一化」有什么作用？](https://www.zhihu.com/question/20455227/answer/370658612)
