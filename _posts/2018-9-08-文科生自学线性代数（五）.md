# 第五章 特征值与特征向量



## 5.1 特征向量与特征值

$A$为$n×n$矩阵，$x$为非零向量，若存在数$\lambda $使$Ax=\lambda x$成立，则称$\lambda $为$A$的**特征值**，$x$称为对应于$\lambda $的**特征向量**.

不能用行化简求特征值，矩阵$A$的阶梯形通常不显示出$A$的特征值.

$\lambda $是$A$的特征值当且仅当方程$(A-\lambda I)x=0$有平凡解.方程的所有解的集合就是矩阵$A-\lambda I$的零空间.因此，该集合是$\mathbb{R}^{n}$的子空间，称为$A$的对应于$\lambda $的**特征空间**. 特征空间由零空间和所有对应于$\lambda $的特征向量组成.

**特征值能被准确求出的特例**：

1. 三角矩阵的主对角线的元素是其特征值.
2. $\lambda _1,\cdots ,\lambda _r$是$n×n$矩阵$A$相异的特征值，$v_1,\cdots ,v_r$是与$\lambda _1,\cdots ,\lambda _r$对应的特征向量，那么向量集合$\begin{Bmatrix}v_1,\cdots ,v_n\end{Bmatrix}$线性无关.

**特征向量与差分方程**：若$A$是$n×n$矩阵，那么$x_{k+1}=Ax_k(k=0,1,2,\cdots )$是$\mathbb{R}^{n}$的序列$\begin{Bmatrix}x_k\end{Bmatrix}$的递归表示，方程的解是描述序列$\begin{Bmatrix}x_k\end{Bmatrix}$的每个$x_k$的显式公式，公式不直接依赖于$A$和序列前面的项，而是依赖于初始项$x_0$. 构造方程的解的最简单方法是取$A$的一个特征向量$x_0$和它对应的特征值$\lambda $，然后令$x_k=\lambda ^kx_0(k=1,2,\cdots )$. 这就是方程的解，解的线性组合仍然是方程的解。这是因为$Ax_k=A(\lambda ^kx_0)=\lambda ^k(Ax_0)=\lambda ^k(Ax_0)=\lambda ^{k+1}x_0=x_{k+1}$.



## 5.2 特征方程

**行列式**（3.2节）：设$A$是$n×n$矩阵，$U$是对$A$作行替换和行交换（不作行倍乘）所得到的任一阶梯形矩阵，$r$是行交换的次数，那么，当$A$可逆时，$A$的行列式为$detA=(-1)^r\cdot (\text{U的主元乘积} )$；当$A$不可逆时，$A$的行列式为0.

**特征方程**：数值方程$det(A-\lambda I)=0$称为$A$的特征方程.

如果$A$是$n×n$矩阵，那么$det(A-\lambda I)$是$n$次多项式，称为$A$的**特征多项式**.

一般地，把特征值$\lambda $作为特征方程根的重数称为是$\lambda $的**（代数）重数**（因式在特征多项式出现的次数）.

假如$A$和$B$是$n×n$矩阵，如果存在可逆矩阵$P$，使得$P^{-1}AP=B$，或等价地$A=PBP^{-1}$，则称$A$相似于$B$.记$Q=P^{-1}$，则有$Q^{-1}BQ=A$，即$B$也相似于$A$，故$A$和$B$是相似的.把$A$变成$P^{-1}AP$的变换称为**相似变换**.

若$n×n$矩阵$A$和$B$是**相似的**，那么它们有相同的特征多项式，从而有相同的特征值（和相同的重数）.

相似性与行等价不是一回事.（假如$A$行等价于$B$，则存在可逆矩阵$E$，使得$B=EA$）对矩阵作行变换通常会改变矩阵的特征值.

另：$\vec{{v}'}$是基$V_2$下的点，$\vec{v}$是基$V_1$下的点.而矩阵$P$实际上是$V_2$在$V_1$下的坐标，它的列向量是特征向量，特征向量确定了运动的方向，也就是说$P$做的运动是旋转改变方向.$\vec{{v}'}$左乘$P$就获得了$\vec{v}$，即$P\vec{{v}'}$点还在那个位置，但是基已经发生了变化，变成了基$V_1$下的点.接着在$V_1$下通过$A$进行线性变换，即$AP\vec{{v}'}$，再通过$P^{-1}$变回$V_2$下的点，即$P^{-1}AP\vec{{v}'}$，综上我们可以有$B\vec{{v}'}=P^{-1}AP\vec{{v}'}$，所以有$B=P^{-1}AP$.那么$B$和$A$互为相似矩阵.（学习内容来自**微信公众号马同学**，侵删）

## 5.3 对角化

**对角化定理**：$n×n$矩阵$A$可对角化的充分必要条件是$A$有$n$个线性无关的特征向量.事实上，$A=PDP^{-1}$，$D$为对角矩阵的充分必要条件是$P$的列向量是$A$的$n$个线性无关的特征向量.此时，$D$的主对角线上的元素分别是$A$的对于于$P$中特征向量的特征值.换句话说，$A$可对角化的充分必要条件是有足够的特征向量形成$\mathbb{R}^{n}$的基，我们称这样的基为**特征向量基**.

**矩阵的对角化**：即求可逆矩阵$P$和对角矩阵$D$，使得$A=PDP^{-1}$.对角化分四步完成.

1. **求出$A$的特征值**.
2. **求$A$的3个线性无关的特征向量**.
3. **用特征向量构造矩阵$P$**.
4. **按矩阵$P$的顺序，用对应的特征值构造矩阵$D$并验证$P$和$D$是否正确（$AP=DP$）**.

有$n$个相异特征值的$n×n$矩阵可对角化，但这不意味着没有$n$个相异特征值就不可对角化.

设$A$是$n×n$矩阵，其相异的特征值是$\lambda _1,\cdots ,\lambda_p$.

1. 对于$1\leqslant k\leqslant p$,$\lambda _k$的特征空间的维数小于或等于$\lambda _k$的代数重数.
2. 矩阵$A$可对角化的充分必要条件是所有不同特征空间的维数之和为$n$.即每个$\lambda _k$的特征空间的维数等于$\lambda _k$的代数重数.
3. 若$A$可对角化，$ß_k$是对应于$\lambda _k$的特征空间的基，那么，集合$ß_1,\cdots ,ß_p$中所有向量的集合是$\mathbb{R}^{n}$的特征向量基.



## 5.4 特征向量与线性变换

**对角矩阵表示**：设$A=PDP^{-1}$，其中$D$为$n×n$对角矩阵，若$\mathbb{R}^{n}$的基$ß$由$P$的列向量组成，那么$D$是变换$x\mapsto Ax$的$ß$-矩阵.

这实际上是特征值分解，即把可对角化矩阵分解为由其特征值和特征向量表示的矩阵之积，特征向量确定运动的方向，特征值确定运动的速度。$D$进行拉伸，$P$和$P^{-1}$进行旋转。



## 5.5 复特征值

设$A$是$2×2$实矩阵，有复特征值$\lambda =a-bi(b\neq 0)$及对应的$\mathbb{C}^{2}$中的复特征向量$v$，$A=PCP^{-1}$，其中$P=[REv \quad IMv],C=\begin{bmatrix}a & -b\\ b & a\end{bmatrix}$.



## 5.6 离散动力系统

略



## 5.7 微分方程中的应用

略



## 5.9 特征值的迭代估计

**估计严格占优特征值的幂算法**：（严格占优特征值是该特征值的绝对值比其他特征值的都大）

1. 选择一个最大分量为1的初始向量$x_0$.

2. 对$k=0,1,\cdots ,$

   1. 计算$Ax_k$.

   2. 设$\mu _k$是$Ax_k$中绝对值最大的一个分量.

   3. 计算$x_{k+1}=(1/\mu _k)Ax_k$.

3. 几乎对所有选择的$x_0$，序列$\begin{Bmatrix}\mu _k\end{Bmatrix}$近似于主特征值，而序列$\begin{Bmatrix}x _k\end{Bmatrix}$近似于对应的特征向量.

**估计$A$的特征值$\lambda $的逆幂法**：

1. 选择一个非常接近于$\lambda $的初始值$\alpha $.
2. 选择一个最大分量为1的初始向量$x_0$.
3. 对$k=0,1,\cdots ,$
   1. 从$(A-\alpha I)y_k=x_k$解出$y_k$.
   2. 设$\mu _k$是$y_k$中绝对值最大的一个分量.
   3. 计算$v_k=\alpha +(1/\mu _k)$.
   4. 计算$x_{k+1}=(1/\mu _k)y_k$.
4. 几乎对所有选择的$x_0$，序列$\begin{Bmatrix}v _k\end{Bmatrix}$趋向于$A$的特征值$\mu $，而序列$\begin{Bmatrix}x _k\end{Bmatrix}$近似于对应的特征向量.

